data:
  db_path: "data/noshow.db"
  table_name: "noshow"
  required_columns:
    - "booking_id"
    - "no_show"
    - "branch"
    - "booking_month"
    - "arrival_month"
    - "arrival_day"
    - "checkout_month"
    - "checkout_day"
    - "country"
    - "first_time"
    - "room"
    - "price"
    - "platform"
    - "num_adults"
    - "num_children"

preprocessing:
  test_size: 0.2
  random_state: 42
  impute_room_strategy: "median"
  impute_price_strategy: "median"
  column_mappings:
    identifier:
      booking_id: "booking_id"
    target:
      no_show: "no_show"
    numerical:
      price: "price"
      num_adults: "num_adults" 
      num_children: "num_children"
    categorical:
      branch: "branch"
      room: "room"
      country: "country"
      platform: "platform"
    temporal:
      arrival_month: "arrival_month"
      checkout_month: "checkout_month"
      booking_month: "booking_month"
      arrival_day: "arrival_day"
      checkout_day: "checkout_day"
    boolean:
      first_time: "first_time"

training:
  cv_folds: 5
  scoring_metric: "f1"                    # "accuracy", "f1", "f1_macro", "precision", "recall", "roc_auc"
  save_model: true
  model_output_path: "models/trained_model.pkl"
  tuning: false                               # false=no tuning, run model, true=tune then run model
  select_feature: false                          # false=use all features, true=use selectFromModel features
  drop_feature: false                           # drop features according to feature_selection -> drop_features
  cross_validate: false                      # true=perform cross validation during training, false=skip cross validation

feature_selection:
  feature_selection_threshold: "mean"           # "median", "mean"
  features_to_drop:                               # Manual select features to drop
  - 'one_hot__branch_changi'
  - 'one_hot__branch_orchard'
  #- 'remainder__country'
  - 'remainder__first_time'
  #- 'robust__price'
  - 'minmax__num_adults'
  - 'minmax__num_children'
  - 'remainder__arrival_day'
  - 'remainder__checkout_month'
  - 'remainder__checkout_day'
  - 'remainder__room'
  - 'remainder__platform'
  - 'remainder__has_children'
  #- 'remainder__stayed_days'
  #- 'remainder__arrival_month_sin'
  #- 'remainder__arrival_month_cos'
  #- 'remainder__checkout_month_sin'
  #- 'remainder__checkout_month_cos'
  #- 'remainder__booking_month_sin'
  #- 'remainder__booking_month_cos'
  #- 'remainder__arrival_day_sin'
  #- 'remainder__arrival_day_cos'
  #- 'remainder__checkout_day_sin'
  #- 'remainder__checkout_day_cos'
  - 'remainder__booking_month'
  - 'remainder__arrival_month'


tuning:
  search_strategy: "grid"                                 # "grid", "random"
  n_iter: 20
  n_jobs: -1
  random_state: 42
  hyperparameters:                                 # Hyperparameters parameter grid for tuning
    random_forest:
      n_estimators: [100, 200, 300, 400]
      max_depth: [15, 20, 25, 30, null]
      min_samples_split: [50, 100, 200]
      min_samples_leaf: [25, 50, 100]
      max_features: [0.3, 0.5, 'sqrt', 'log2']
      class_weight: ['balanced']
    logistic_regression:
      C: [0.1, 0.5, 1.0, 10.0]
      max_iter: [2000]
      #penalty: ['l1', 'l2']
      penalty: ['l2']
      solver: ['liblinear', 'saga', 'lbfgs']
      class_weight: ['balanced']
    xgboost:
      n_estimators: [50, 100, 200, 300]
      max_depth: [3, 6, 9, 10]
      learning_rate: [0.01, 0.1, 0.2]
      subsample: [0.8, 0.9, 1.0]
      scale_pos_weight: [1.0, 1.5, 2.0, 2.5]
    svm:
      C: [0.1, 1.0, 10.0]
      kernel: ['rbf', 'linear']
      class_weight: ['balanced']


# Optimized parameters for model training
model:
  algorithm: "random_forest"                # "random_forest", "logistic_regression", "xgboost", "svm"
  hyperparameters:
    random_forest:
      n_estimators: 300
      min_samples_split: 50
      min_samples_leaf: 25
      max_features: 0.3
      max_depth: 25
      random_state: 42
      class_weight: "balanced"
    logistic_regression:
      random_state: 42
      solver: 'liblinear'
      penalty: 'l2'
      max_iter: 2000              
      C: 10
      class_weight: "balanced"
    xgboost:
      random_state: 42
      subsample: 0.9
      n_estimators: 100
      max_depth: 10
      learning_rate: 0.2
      scale_pos_weight: 1.0
    svm:
      C: 1.0
      kernel: "rbf"
      random_state: 42
      class_weight: "balanced"


evaluation:
  save_reports: true
  reports_path: "reports/"
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1"
    - "f1_macro"
    - "roc_auc"
