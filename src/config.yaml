data:
  db_path: "data/noshow.db"
  table_name: "noshow"
  required_columns:
    - "booking_id"
    - "no_show"
    - "branch"
    - "booking_month"
    - "arrival_month"
    - "arrival_day"
    - "checkout_month"
    - "checkout_day"
    - "country"
    - "first_time"
    - "room"
    - "price"
    - "platform"
    - "num_adults"
    - "num_children"

preprocessing:
  test_size: 0.3
  random_state: 42
  impute_room_strategy: "median"
  impute_price_strategy: "median"
  column_mappings:
    identifier:
      booking_id: "booking_id"
    target:
      no_show: "no_show"
    numerical:
      price: "price"
      num_adults: "num_adults" 
      num_children: "num_children"
    categorical:
      branch: "branch"
      room: "room"
      country: "country"
      platform: "platform"
    temporal:
      arrival_month: "arrival_month"
      checkout_month: "checkout_month"
      booking_month: "booking_month"
      arrival_day: "arrival_day"
      checkout_day: "checkout_day"
    boolean:
      first_time: "first_time"

training:
  cv_folds: 5
  scoring_metric: "roc_auc"                    # "accuracy", "f1", "f1_macro", "precision", "recall", "roc_auc"
  save_model: true
  model_output_path: "models/trained_model.pkl"
  tuning: True                                # False=no tuning, run model, True=tune then run model
  select_feature: False                          # False=use all features, True=use selectFromModel features
  drop_feature: False                           # Drop features according to feature_selection -> drop_features
  cross_validate: False                      # True=perform cross validation during training, False=skip cross validation

feature_selection:
  feature_selection_threshold: "median"           # "median", "mean"
  features_to_drop:                               # Manual select features to drop
    - "minmax__num_children"
    - "remainder__arrival_month"
    - "remainder__arrival_day"
    - "remainder__checkout_month"
    - "remainder__checkout_day"
    - "remainder__arrival_month_sin"
    - "remainder__arrival_month_cos"
    - "remainder__checkout_month_sin"
    - "remainder__checkout_month_cos"
    - "remainder__arrival_day_sin"
    - "remainder__arrival_day_cos"
    - "remainder__checkout_day_sin"
    - "remainder__checkout_day_cos"
    - "remainder__booking_month"
    - "remainder__booking_month_sin"
    - "remainder__booking_month_cos"


tuning:
  search_strategy: "random"                                 # "grid", "random"
  n_iter: 20
  n_jobs: -1
  random_state: 42
  hyperparameters:                                 # Hyperparameters parameter grid for tuning
    random_forest:
      n_estimators: [100, 200, 300, 400]
      max_depth: [15, 20, 25, 30, null]
      min_samples_split: [50, 100, 200]
      min_samples_leaf: [25, 50, 100]
      max_features: [0.3, 0.5, 'sqrt', 'log2']
    logistic_regression:
      C: [0.1, 0.5, 1.0, 10.0]
      max_iter: [2000]
      penalty: ['l1', 'l2']
      solver: ['liblinear', 'saga']
    xgboost:
      n_estimators: [50, 100, 200, 300]
      max_depth: [3, 6, 9]
      learning_rate: [0.01, 0.1, 0.2]
      subsample: [0.8, 0.9, 1.0]
    svm:
      C: [0.1, 1.0, 10.0]
      kernel: ['rbf', 'linear']


# Optimized parameters for model training
model:
  algorithm: "logistic_regression"                # "random_forest", "logistic_regression", "xgboost", "svm"
  hyperparameters:
    random_forest:
      n_estimators: 300
      min_samples_split: 50
      min_samples_leaf: 25
      max_features: 0.3
      max_depth: 25
      random_state: 42   
    logistic_regression:
      random_state: 42
      solver: 'saga'
      penalty: 'l1'
      max_iter: 2000              
      C: 0.1
    xgboost:
      random_state: 42
      subsample: 0.8
      n_estimators: 300
      max_depth: 3
      learning_rate: 0.1 
    svm:
      C: 1.0
      kernel: "rbf"
      random_state: 42


evaluation:
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1"
    - "f1_macro"
    - "roc_auc"
  save_reports: true
  reports_path: "reports/"
